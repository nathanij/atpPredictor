{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model-Building.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMYpY7oBIkhrJl2SeF4NhW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathanij/atpPredictor/blob/main/Model_Building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup"
      ],
      "metadata": {
        "id": "uCPaEYY1PYqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tables\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import datetime\n",
        "import h5py\n",
        "from google.colab import drive\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ccPH5w9tPr38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use processed data"
      ],
      "metadata": {
        "id": "IydOJsgZPTUv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Ak5VnwPMnK"
      },
      "outputs": [],
      "source": [
        "data = pd.read_hdf('/content/drive/MyDrive/tennisData/finished(key=a).h5', key = 'a')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete definitely unwanted columns"
      ],
      "metadata": {
        "id": "7zIOOgLSfAV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drops = ['ind', 'tourney_id']\n",
        "for d in drops:\n",
        "  data = data.drop(d, axis = 1)\n",
        "plys = ['p0_', 'p1_']\n",
        "pDrops = ['id']\n",
        "for p in plys:\n",
        "  for d in pDrops:\n",
        "    data = data.drop(p+d, axis = 1)"
      ],
      "metadata": {
        "id": "5K_PZgG5fDiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter out whatever subset you want to train on"
      ],
      "metadata": {
        "id": "SOGx2r9YS5Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data.tourney_date >= 20080000] #cut out first 3 years of data"
      ],
      "metadata": {
        "id": "43nZVKWsS7xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop Qualifiers"
      ],
      "metadata": {
        "id": "uzid9z_eirmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drops = ['tourney_date']\n",
        "for d in drops:\n",
        "  data = data.drop(d, axis = 1)\n",
        "plys = ['p0_', 'p1_']\n",
        "pDrops = []\n",
        "for p in plys:\n",
        "  for d in pDrops:\n",
        "    data = data.drop(p+d, axis = 1)"
      ],
      "metadata": {
        "id": "UNZ4FBn1YBRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seperate training and validation"
      ],
      "metadata": {
        "id": "m1Lde90ujI2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True) #shuffles rows\n",
        "training = data.copy()\n",
        "validation = training[-7000:]\n",
        "training = training[:-7000]"
      ],
      "metadata": {
        "id": "lyc1ZvPoPGSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Found models were unbalanced p0 vs p1 so replicate and flip all training data"
      ],
      "metadata": {
        "id": "WSAuSRMUvr1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oppo = training.copy()\n",
        "for row in range(len(oppo)):\n",
        "  for col in oppo:\n",
        "    if col[:2] == 'p0':\n",
        "      tmp = oppo.loc[row,col]\n",
        "      end = col[2:]\n",
        "      oppo.loc[row, col] = oppo.loc[row, 'p1' + end]\n",
        "      oppo.loc[row, 'p1' + end] = tmp\n",
        "  oppo.loc[row, 'winner'] = abs(oppo.loc[row, 'winner'] - 1)"
      ],
      "metadata": {
        "id": "29jI0cGxvxwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = pd.concat([training, oppo], ignore_index = True)"
      ],
      "metadata": {
        "id": "Dd4rkQru7TSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = training.sample(frac=1).reset_index(drop=True) #shuffles rows\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "y_train = training.pop('winner')\n",
        "y_train = np_utils.to_categorical(y_train, 2)\n",
        "x_train = training\n",
        "x_train = np.asarray(x_train).astype(np.float32)\n",
        "y_val = validation.pop('winner')\n",
        "y_val = np_utils.to_categorical(y_val, 2)\n",
        "x_val = validation\n",
        "x_val = np.asarray(x_val).astype(np.float32)"
      ],
      "metadata": {
        "id": "dK3Pw_Ed1OQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up checkpoint to save best model while training"
      ],
      "metadata": {
        "id": "k2o16tUrXId7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_filepath = '/content/drive/MyDrive/Models/bestAcc'\n",
        "loss_filepath = '/content/drive/MyDrive/Models/bestLoss'\n",
        "acc_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=acc_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "loss_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=loss_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=20)"
      ],
      "metadata": {
        "id": "Z3SzZuliXGwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(46, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.1)),\n",
        "  layers.Dense(2048, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.1)),\n",
        "  layers.Dropout(0.1),\n",
        "  layers.Dense(2048, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.1)),\n",
        "  layers.Dropout(0.1), \n",
        "  layers.Dense(2048, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.1)),\n",
        "  layers.Dropout(0.1), \n",
        "  layers.Dense(4096, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.1)),\n",
        "  layers.Dropout(0.1),                        \n",
        "  layers.Dense(2, activation = 'softmax')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ogXUKFDcXrWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "wc82GJ3qYvE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size = 128, epochs = 1000, shuffle=True, callbacks = [acc_callback, loss_callback, early])"
      ],
      "metadata": {
        "id": "baRdiHd1Yok_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accModel = keras.models.load_model('/content/bestAccModel')\n",
        "lossModel = keras.models.load_model('/content/bestLossModel')"
      ],
      "metadata": {
        "id": "Q0SvSWCdV-AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accModel.evaluate(x_val, y_val)"
      ],
      "metadata": {
        "id": "OxdyN5HSWCtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lossModel.evaluate(x_val, y_val)"
      ],
      "metadata": {
        "id": "kahT3ORUvTqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accModel.save('denseAcc') #save\n",
        "!cp -r denseAcc /content/drive/MyDrive/Models\n",
        "lossModel.save('denseLoss')\n",
        "!cp -r denseLoss /content/drive/MyDrive/Models"
      ],
      "metadata": {
        "id": "NhUzTnXykOCQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}